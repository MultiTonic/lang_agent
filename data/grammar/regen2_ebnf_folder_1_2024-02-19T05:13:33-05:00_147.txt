
#+begin_src input
We are bootstrapping a new system using EBNF grammars.
We want to make an ebnf grammar that is super detailed.
for each rule we want to create a nameing rule for the rules that have them all start with prd. each token should be called tkn.
if a token is used in a rule lets make it prd_<prod name>_tkn_<token name>
Here is the code we wrote so far 
(*
folder

   take inputs :
   grammar : A
   Previous Results : D initially, Initial example : B
   New Example : C
   Created new output D.
   Test D. If good, repeat loop with new D. Othewise feed error back to create new D up to 3 times.
   start with this following code and rewrite it to suit our needs.
*)

let rec fold_left op acc = function
  | []   -> acc
  | h :: t -> fold_left op (op acc h) t
                
 ENDSRC . Lets create a new EBNF that is more expressive and explicit.

#+end_src
#+begin_src output mixtral
 Result: Here is an example of how you can define your EBNF grammar with the specified naming rules:
```
prod_folder -> '{' [ prd_inputs tkn_input { ',' prd_inputs tkn_input } ] '}' ;
prd_inputs -> prd_grammar tkn_grammar
            | prd_previousResults tkn_previousResults
            | prd_newExample tkn_newExample ;
prd_grammar -> 'A' ;
prd_previousResults -> 'D' ;
prd_newExample -> 'C' ;
tkn_input -> String | Number | Symbol ;
tkn_grammar -> 'A' ;
tkn_previousResults -> 'D' ;
tkn_newExample -> 'C' ;
```
In this example, `prod_*` rules represent the non-terminals and `tkn_*` represents the terminal symbols. The `[]` and `{}` indicate optional and repetition respectively. Also, I assume that String, Number, Symbol are the token names which you have used in your lexer or scanner.

This is a simple example, depending on the complexity of your grammar you might need to add more rules or make modifications to this one.
#+end_src
